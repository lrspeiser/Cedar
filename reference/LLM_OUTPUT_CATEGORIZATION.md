# LLM Output Categorization System

## üéØ Overview

The LLM Output Categorization System automatically routes content generated by the LLM to the appropriate tabs in Cedar. This ensures that data, visualizations, analysis results, and other outputs appear in the correct locations for easy access and organization.

## üîß Problem Solved

### **Before**: Content Scattered Everywhere
- LLM generated data but it didn't appear in the Data tab
- Visualizations were created but not visible in the Images tab
- Analysis results were lost in the notebook
- Users had to manually organize content

### **After**: Automatic Content Routing
- Data automatically appears in the Data tab
- Visualizations are saved to the Images tab
- Analysis results go to the Write-up tab
- References are added to the References tab
- Code utilities are saved to the Code tab

## üèóÔ∏è Technical Implementation

### **1. Enhanced LLM Prompt** (`prompts/plan.txt`)

The research planning prompt now includes explicit categorization instructions:

```python
# CATEGORY: data
# DESCRIPTION: Customer churn dataset with features and target variable
# FILENAME: customer_churn_data.csv
import pandas as pd
import numpy as np

# Generate sample customer data
np.random.seed(42)
n_customers = 1000
data = {
    'customer_id': range(1, n_customers + 1),
    'tenure_months': np.random.randint(1, 72, n_customers),
    'monthly_charges': np.random.uniform(30, 150, n_customers),
    'total_charges': np.random.uniform(100, 5000, n_customers),
    'churn': np.random.choice([0, 1], n_customers, p=[0.8, 0.2])
}

df = pd.DataFrame(data)
df.to_csv('customer_churn_data.csv', index=False)
print("Customer churn dataset created with 1000 records")
```

### **2. Backend Categorization Engine** (`src-tauri/src/main.rs`)

#### **Main Categorization Function**
```rust
async fn categorize_code_output(
    code: &str,
    output: &str,
    project_id: &str,
    state: &State<'_, AppState>,
) -> Result<(), String>
```

#### **Output Categories**
- **data**: CSV files, datasets, dataframes, raw data
- **visualization**: Charts, graphs, plots (Vega-Lite/Plotly JSON)
- **analysis**: Statistical results, insights, findings
- **code**: Reusable functions, utilities, scripts
- **reference**: External sources, citations, documentation
- **write_up**: Final reports, summaries, conclusions

### **3. Parsing Engine**

#### **Header-Based Parsing**
The system looks for specific headers in LLM code:
- `# CATEGORY:` - Specifies the output type
- `# DESCRIPTION:` - Provides a description
- `# FILENAME:` - Specifies the filename

#### **Legacy Fallback**
For code without headers, the system uses pattern matching:
- File extensions (`.csv`, `.json`, `.png`, etc.)
- Code patterns (`pd.read_csv`, `plt.savefig`, etc.)
- Output content analysis

### **4. Integration Points**

#### **Code Execution** (`execute_code`)
```rust
// Categorize the output if we have a project ID
if !project_id.is_empty() {
    if let Err(e) = categorize_code_output(&request.code, &output, &project_id, &state).await {
        println!("‚ö†Ô∏è Failed to categorize code output: {}", e);
    }
}
```

#### **Research Execution** (`execute_research_steps_background`)
```rust
// Categorize the output into appropriate tabs
if let Err(e) = categorize_code_output(&cell.content, &exec_result.stdout, &project_id, &state).await {
    println!("‚ö†Ô∏è Failed to categorize code output: {}", e);
}
```

## üìä **Category-Specific Processing**

### **Data Category**
- **Detection**: `.csv`, `.json` files, `DataFrame` operations
- **Storage**: Saved to project's data files
- **Tab**: Appears in Data tab
- **Example**: Customer datasets, survey results, time series data

### **Visualization Category**
- **Detection**: Vega-Lite/Plotly JSON, `.png` files, `plt.savefig`
- **Storage**: Saved as visualization objects or image files
- **Tab**: Appears in Images tab
- **Example**: Bar charts, scatter plots, heatmaps

### **Analysis Category**
- **Detection**: Statistical results, correlation matrices, findings
- **Storage**: Saved to write-up content
- **Tab**: Appears in Write-up tab
- **Example**: Statistical summaries, hypothesis test results

### **Code Category**
- **Detection**: Utility functions, reusable scripts
- **Storage**: Saved as code files
- **Tab**: Appears in Code tab
- **Example**: Data preprocessing functions, analysis utilities

### **Reference Category**
- **Detection**: External sources, citations
- **Storage**: Saved as reference objects
- **Tab**: Appears in References tab
- **Example**: Academic papers, documentation links

## üîÑ **Workflow Integration**

### **1. Research Planning**
- LLM generates plan with categorized outputs
- Each step specifies what type of content it will create

### **2. Code Execution**
- Code runs and produces output
- Categorization system analyzes the output
- Content is automatically routed to appropriate tabs

### **3. User Experience**
- Users see content appear in the correct tabs
- No manual organization required
- Consistent content structure across projects

## üß™ **Testing**

### **Test Script** (`test-categorization-system.js`)
Comprehensive test that verifies:
- ‚úÖ Categorized data generation
- ‚úÖ Categorized visualization creation
- ‚úÖ Categorized analysis results
- ‚úÖ Legacy code categorization
- ‚úÖ Content routing to correct tabs

### **Manual Testing Steps**
1. Create a new research project
2. Start research with data analysis goal
3. Execute code with categorization headers
4. Verify content appears in correct tabs
5. Check that legacy code is also categorized

## üéØ **Benefits Achieved**

1. **Automatic Organization**: Content is automatically sorted into appropriate tabs
2. **Improved Discoverability**: Users can easily find generated content
3. **Consistent Structure**: All projects follow the same organization pattern
4. **Reduced Manual Work**: No need to manually move content between tabs
5. **Better User Experience**: Content appears where users expect it

## üìù **Usage Examples**

### **Data Generation**
```python
# CATEGORY: data
# DESCRIPTION: Monthly sales data for Q1 2024
# FILENAME: q1_sales_2024.csv
import pandas as pd
import numpy as np

# Generate sales data
dates = pd.date_range('2024-01-01', '2024-03-31', freq='D')
sales = np.random.poisson(100, len(dates))
df = pd.DataFrame({'date': dates, 'sales': sales})
df.to_csv('q1_sales_2024.csv', index=False)
print("Q1 2024 sales data created")
```

### **Visualization Creation**
```python
# CATEGORY: visualization
# DESCRIPTION: Sales trend line chart
# FILENAME: sales_trend.json
import pandas as pd
import json

df = pd.read_csv('q1_sales_2024.csv')
df['date'] = pd.to_datetime(df['date'])

# Create Vega-Lite specification
vega_spec = {
    "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
    "description": "Q1 2024 Sales Trend",
    "data": {"values": df.to_dict('records')},
    "mark": "line",
    "encoding": {
        "x": {"field": "date", "type": "temporal"},
        "y": {"field": "sales", "type": "quantitative"}
    },
    "title": "Daily Sales Trend - Q1 2024"
}

with open('sales_trend.json', 'w') as f:
    json.dump(vega_spec, f, indent=2)
print("Sales trend visualization created")
```

### **Analysis Results**
```python
# CATEGORY: analysis
# DESCRIPTION: Sales performance analysis
# FILENAME: sales_analysis.txt
import pandas as pd

df = pd.read_csv('q1_sales_2024.csv')

analysis = f"""
Q1 2024 SALES ANALYSIS
=====================

Summary Statistics:
- Total sales: {df['sales'].sum():,}
- Average daily sales: {df['sales'].mean():.1f}
- Best day: {df.loc[df['sales'].idxmax(), 'date']} ({df['sales'].max()} sales)
- Worst day: {df.loc[df['sales'].idxmin(), 'date']} ({df['sales'].min()} sales)

Monthly Breakdown:
{df.groupby(df['date'].dt.month)['sales'].agg(['sum', 'mean', 'count'])}
"""

with open('sales_analysis.txt', 'w') as f:
    f.write(analysis)
print("Sales analysis completed")
```

## üîÆ **Future Enhancements**

1. **Smart Categorization**: AI-powered content type detection
2. **Custom Categories**: User-defined categorization rules
3. **Batch Processing**: Categorize multiple outputs at once
4. **Content Relationships**: Link related content across tabs
5. **Export Integration**: Categorize content for external export

## üìö **Related Documentation**

- [Data Management System](DATA_MANAGEMENT_SYSTEM.md)
- [Visualization System](VISUALIZATION_SYSTEM.md)
- [Research Planning](RESEARCH_PLAN_SYSTEM.md)
- [Session Persistence](SESSION_PERSISTENCE_IMPLEMENTATION.md) 